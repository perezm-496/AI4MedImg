{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "004_Nesterov-DataLoader-MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnjvtCNV/Jb6uj3k6+yw8y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perezm-496/AI4MedImg/blob/main/004_Nesterov_DataLoader_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thkwrETejsdH"
      },
      "source": [
        "# MNIST dataset\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(), # Tensor\n",
        "        transforms.Normalize((0.1307,), # media\n",
        "                             (0.3081,) # std\n",
        "                             ) \n",
        "        ])\n",
        "\n",
        "dataset = torchvision.datasets.MNIST('./',\n",
        "                                     train=True,\n",
        "                                     download=True,\n",
        "                                     transform=transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6W9v-Fu8O-l_",
        "outputId": "a6cb6d20-9e36-49ed-b62b-342fd55e86de"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img0, t = dataset[100]\n",
        "print(t)\n",
        "print(img0.shape)\n",
        "img0 = img0.numpy().reshape(28, 28)\n",
        "plt.imshow(img0)\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([1, 28, 28])\n",
            "60000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Rl7V_eO5BU",
        "outputId": "2942838b-f065-44f5-e9fe-3573f1625f3f"
      },
      "source": [
        "# encargado de los batchs\n",
        "trainloader = torch.utils.data.DataLoader(dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "\n",
        "# Modelo\n",
        "mdl = torch.nn.Sequential( torch.nn.Flatten(),\n",
        "                           torch.nn.Linear(28*28, 1024),\n",
        "                           torch.nn.ReLU(),\n",
        "                           torch.nn.Linear(1024, 10),\n",
        "                           torch.nn.Softmax()\n",
        "                           )\n",
        "\n",
        "criterion = torch.nn.Ca\n",
        "\n",
        "optimizer = torch.optim.SGD(mdl.parameters(),\n",
        "                           lr = 0.1,\n",
        "                           momentum = 0.9)\n",
        "\n",
        "# Single training epoch done in batchs.\n",
        "epoch_loss = 0\n",
        "for x, t in iter(trainloader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y = mdl(x)\n",
        "    loss = criterion(y, t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.detach().item()\n",
        "\n",
        "print(\"Loss value in this epoch: {}\".format(\n",
        "    epoch_loss\n",
        "))\n",
        "\n",
        "# Test the result of training on test\n",
        "\n",
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST('./',\n",
        "                                     train=False,\n",
        "                                     download=True,\n",
        "                                     transform=transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset, \n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                num_workers=2)\n",
        "\n",
        "epoch_acc = 0\n",
        "for x, t in iter(test_loader):\n",
        "    y = mdl(x) # Logit\n",
        "    pred = torch.argmax(y)\n",
        "    acc = torch.sum(pred == t)\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "print(\"Acc on test dataset: {}\".format(epoch_acc/len(test_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value in this epoch: nan\n",
            "Acc on test dataset: 0.5923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIL-9nPekY5O"
      },
      "source": [
        "def train_epoch(mdl, criterion, optimizer, dataloader):\n",
        "    epoch_loss = 0\n",
        "    for x, t in iter(trainloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y = mdl(x)\n",
        "        loss = criterion(y, t)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.detach().item()\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "def compute_acc(mdl, dataloader):\n",
        "    epoch_acc = 0\n",
        "    for x, t in iter(test_loader):\n",
        "        y = mdl(x) # Logit\n",
        "        pred = torch.argmax(y)\n",
        "        acc = torch.sum(pred == t)\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "kEs6AHtlkyOQ",
        "outputId": "46745d6a-691e-4fa2-f372-044512ed0e40"
      },
      "source": [
        "total_epochs = 100\n",
        "loss_list = [ ]\n",
        "acc_list = [ ]\n",
        "for epoch in range(total_epochs):\n",
        "    epoch_loss = train_epoch(\n",
        "        mdl,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        trainloader\n",
        "    )\n",
        "    loss_list.append(epoch_loss)\n",
        "    if (epoch+1)%10 == 0:\n",
        "        # Test every 10 epochs\n",
        "        epoch_acc = compute_acc(\n",
        "            mdl,\n",
        "            trainloader\n",
        "        )\n",
        "        acc_list.append(epoch_acc)\n",
        "\n",
        "print(loss_list)\n",
        "print(epoch_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-cca64ce3a6d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrainloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-89a230bcf130>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(mdl, criterion, optimizer, dataloader)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHuGAYGQqSum"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}